# Streamlit-FAQ-BOT
Proof-of-Concept bot built in Python


ğŸ“š FAQ-BOT

An intelligent FAQ chatbot powered by Pinecone vector search and Streamlit UI. The bot retrieves answers from a knowledge base using embeddings and provides retrieval-only responses with optional summarization.

The project is containerized with Docker, supports autoscaling on free cloud platforms, and includes monitoring via Prometheus and Grafana.


ğŸš€ Features

RAG (Retrieval-Augmented Generation) pipeline

Embeddings stored & searched in Pinecone

Retrieval-only answers (fast, reliable)

Optional summarization with Flan-T5-Small

Interactive Chat UI

Built with Streamlit

Real-time FAQ chat interface

Containerized Deployment

Dockerfile for reproducible builds

docker-compose.yaml integrates monitoring stack

Compatible with Railway.app, Render, or Hugging Face Spaces


Monitoring & Logging

Prometheus: query per second (QPS), latency

Grafana: dashboard visualization

Simple logging for debugging

Scalable

Runs locally or deploys on free cloud tiers

Ready for autoscaling containers


ğŸ› ï¸ Tech Stack

Language: Python 3.10

Libraries:

pinecone â†’ vector database

transformers â†’ embeddings + summarization (Flan-T5)

streamlit â†’ chatbot interface


Infrastructure:

Docker â†’ containerization

Prometheus + Grafana â†’ monitoring/metrics

docker-compose â†’ orchestration


ğŸ“‚ Project Structure
faq-bot/
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ build_embeddings_pinecone.py   # Index builder
â”‚   â”œâ”€â”€ qa_pinecone.py                 # Retrieval-only QA
â”‚   â”œâ”€â”€ app_conv.py                    # Streamlit chat UI
â”‚
â”œâ”€â”€ secrets.json                       # Stores API keys securely
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ Dockerfile                         # Container image
â”œâ”€â”€ docker-compose.yaml                # Services (FAQ-Bot, Prometheus, Grafana)
â””â”€â”€ README.md                          # Project documentation

âš™ï¸ Setup & Usage
1ï¸âƒ£ Local Setup
# Clone repo
git clone https://github.com/yourusername/faq-bot.git
cd faq-bot


# Create venv
python -m venv venv
source venv/bin/activate   # (Linux/Mac)
venv\Scripts\activate      # (Windows)


# Install dependencies
pip install -r requirements.txt


Add your Pinecone API key + index name to secrets.json:

{
  "PINECONE_API_KEY": "your-key-here",
  "PINECONE_INDEX": "faq-bot"
}


2ï¸âƒ£ Run Locally
# Build embeddings
python rag/build_embeddings_pinecone.py

# Start Streamlit UI
streamlit run rag/app_conv.py


Access at ğŸ‘‰ http://localhost:8501

3ï¸âƒ£ Docker Deployment
docker compose up --build


Services:

FAQ-BOT â†’ http://localhost:8501

Prometheus â†’ http://localhost:9090

Grafana â†’ http://localhost:3000


ğŸ“Š Monitoring

Prometheus scrapes metrics (QPS, latency, errors).

Grafana visualizes dashboards for performance monitoring.

Can be extended with alerts for production.


ğŸŒ Real-World Use Cases

Internal Knowledge Base â†’ Employees query company FAQs

Customer Support â†’ Automated responses before escalating to agents

Education â†’ Students query course material in natural language

Documentation Search â†’ Developers find API usage examples quickly


ğŸš§ Roadmap

 Add WhatsApp/Twilio webhook for chatbot integration

 Improve summarization with larger LLMs (when budget allows)

 CI/CD pipeline for auto-deployment

 Expand dataset with multi-source documents
 

ğŸ¤ Contributing

PRs are welcome! For major changes, open an issue first.


ğŸ“œ License

MIT License â€“ free to use, modify, and distribute.


ğŸ“¬ Contact

LinkedIn: www.linkedin.com/in/unathi-manana
Email: unathimanana77@gmail.com
